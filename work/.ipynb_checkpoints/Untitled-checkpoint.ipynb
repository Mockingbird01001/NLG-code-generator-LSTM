{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "532d077f",
   "metadata": {},
   "source": [
    "# Visualisation Streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc950a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â !pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8af1369a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-08 00:57:23.957 INFO    numexpr.utils: NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st \n",
    "\n",
    "import tensorflow\n",
    "\n",
    "import functions as f\n",
    "from Text import *\n",
    "from LSTM_class import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "33fd3c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Apr  8 03:11:25 2022\n",
    "\n",
    "@author: mockingbird\n",
    "\"\"\"\n",
    "\n",
    "import streamlit as st \n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "import functions as f\n",
    "from Text import *\n",
    "from LSTM_class import *\n",
    "\n",
    "\n",
    "class Visu:\n",
    "    def __init__(self):\n",
    "        self.max_len = 2 # longeur des sequence\n",
    "        self.step = 1 # le pas\n",
    "        self.layer_size = 64 # nombre de neuronnes\n",
    "        # lecture des fichiers\n",
    "        self.input_train = f.read_dir()\n",
    "        # tokeniser le text\n",
    "        self.text_train = Text(self.input_train)\n",
    "        # creation des sequences a partir des tokens\n",
    "        self.seq_train = Sequences(self.text_train, self.max_len, self.step)\n",
    "        # load un ancien model\n",
    "        self.model = self.lstm_model(sequence_length=self.max_len, \n",
    "                                vocab_size=len(self.text_train), \n",
    "                                layer_size=self.layer_size)\n",
    "        self.model = models.load_model('data/out/lstm_model_simple')\n",
    "        # init les equivalent du TF IDF\n",
    "        self.token2ind, self.ind2token = self.text_train.token2ind, self.text_train.ind2token\n",
    "        \n",
    "        \n",
    "    # def pour la creation de notre model\n",
    "    def lstm_model(self, sequence_length, vocab_size, layer_size, embedding=False):\n",
    "        model = models.Sequential()\n",
    "        if embedding:\n",
    "            model.add(layers.Embedding(vocab_size, layer_size))\n",
    "            model.add(layers.Bidirectional(layers.LSTM(layer_size)))\n",
    "            model.add(layers.Dropout(0.5))\n",
    "        else:\n",
    "            model.add(layers.LSTM(layer_size, input_shape=(sequence_length, vocab_size)))\n",
    "            model.add(layers.Dropout(0.5))\n",
    "        model.add(layers.Dense(vocab_size, activation='relu'))\n",
    "        return model\n",
    "        \n",
    "    def prediction_lstm(self, input_prefix):\n",
    "        result = []\n",
    "        # tokenization de la sequence initiale\n",
    "        text_prefix = Text(input_prefix, self.token2ind, self.ind2token)\n",
    "        # prediction a partir d'une sequence\n",
    "        pred = ModelPredict(self.model, text_prefix, self.token2ind, self.ind2token, self.max_len)\n",
    "        for temperature in [1, 0.7, 0.4, 0.1]:\n",
    "            result.append(pred.generate_sequence(10, temperature=temperature))\n",
    "        return result\n",
    "\n",
    "    def call_pred(self):\n",
    "        text = \"\"\"from tensorflow.python.framework import dtypes\"\"\"\n",
    "        return self.prediction_lstm(text)\n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    visualisation = Visu()\n",
    "    res = visualisation.call_pred()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9752fcfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from tensorflow.python.framework import dtypes close_summary_writer: input_rhs, _deprecation.DeprecationWrapper( _convert_object_or_list, ops.convert_to_tensor(got), self._test_dir(\"managed_keep_summary_writer\") embedding_init self._validate_flag_names() distribute_utils. _make_ta(2,'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4c698e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from tensorflow.python.framework import dtypes target.__module__ ragged_hash(self): filter(either ops.device(self._host_device),\"SparseTensor\", self.assertAllClose(a_recon, type(meta_graph_def)) NumpyArrayF32([[1, decorator_name=\\'should_use_result\\','"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9af10ebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from tensorflow.python.framework import dtypes k.__name__.startswith(\"TPUStrategy\") 2.0 @tf_export(v1=[\"train.VocabInfo\"]) features=features, accumulator) array_ops.constant(1.0), 15])\\'i1\\'(b_v tensorflow.python.data.benchmarks'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0397fe0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from tensorflow.python.framework import dtypes cpuinfo(op_index violates os.unlink(temp_file.name) u\"\\\\xea\\\\xea\", warm-starting\"step_marker_location\", self._deserialize(nest.map_structure(rename, b\"ft\"]], accumulation'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf180c12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
